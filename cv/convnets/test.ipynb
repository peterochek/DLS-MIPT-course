{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import Inception3\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Проверяем, доступны ли GPU\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(299), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "\n",
    "classes = tuple(str(i) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0, 1000))\n",
    "    im_val, label = testset[random_characters]\n",
    "    imshow(im_val.data.cpu(), plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extractor = Inception3(num_classes=10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_extractor.parameters())\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.5)\n",
    "\n",
    "model_extractor.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2mk7MNtcUhJ"
   },
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    losses = []\n",
    "  \n",
    "    for idx, data in enumerate(tqdm(train_loader)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if idx % 50 == 0:\n",
    "            losses.append(loss.item())\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_CD9--hcUjs"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaxYIwB3cUmX"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, opt, scheduler, epochs, batch_size):\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "    all_losses = []\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc, losses = fit_epoch(model, train_loader, criterion, opt)\n",
    "            all_losses += losses\n",
    "            print(\"loss\", train_loss)\n",
    "            \n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "    return history, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6G7qbYqcUpL"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "iDXoR8PIdfLD",
    "outputId": "f16c74b1-6c44-45a9-f7a1-88783a656541"
   },
   "outputs": [],
   "source": [
    "history, total_loss = train(model=model_extractor, criterion=criterion, opt=optimizer, scheduler=scheduler, epochs=1 , batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "GpQDWGkfdfQ5",
    "outputId": "de04fca0-5e73-46a0-a28b-f4354643cfb2"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(2,2)\n",
    "\n",
    "ax_1 = fig.add_subplot(gs[0, 0])\n",
    "ax_2 = fig.add_subplot(gs[0, 1])\n",
    "ax_3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "ax_1.set_title('Train Loass')\n",
    "ax_1.set_xlabel('Epoch')\n",
    "ax_1.set_ylabel('Loss')\n",
    "\n",
    "ax_2.set_title('Val  Loss')\n",
    "ax_2.set_xlabel('Epoch')\n",
    "ax_2.set_ylabel('Loss')\n",
    "\n",
    "ax_3.set_title('Every 50th loss')\n",
    "ax_3.set_xlabel('Iteration / 50')\n",
    "ax_3.set_ylabel('Loss')\n",
    "\n",
    "sns.lineplot(ax=ax_1, data=loss);\n",
    "sns.lineplot(ax=ax_2, data=val_loss);\n",
    "sns.lineplot(ax=ax_3, data=total_loss);\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
