{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot(label, n_classes, requires_grad=True):\n",
    "    print(f'{label.shape=}')\n",
    "    print(f'{label=}')\n",
    "    print(f'{n_classes=}')\n",
    "    \n",
    "    one_hot_label = torch.eye(\n",
    "        n_classes, device=device, requires_grad=requires_grad)[label]\n",
    "    one_hot_label = one_hot_label.transpose(1, 3).transpose(2, 3)\n",
    "\n",
    "    return one_hot_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randint(0, 2, (8, 16, 16))\n",
    "\n",
    "# print(a)\n",
    "\n",
    "# b = torch.eye(1)\n",
    "\n",
    "# print(b[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"Boundary Loss proposed in:\n",
    "    Alexey Bokhovkin et al., Boundary Loss for Remote Sensing Imagery Semantic Segmentation\n",
    "    https://arxiv.org/abs/1905.07852\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta0=3, theta=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta0 = theta0\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - pred: the output from model (before softmax)\n",
    "                    shape (N, C, H, W)\n",
    "            - gt: ground truth map\n",
    "                    shape (N, H, w)\n",
    "        Return:\n",
    "            - boundary loss, averaged over mini-bathc\n",
    "        \"\"\"\n",
    "\n",
    "        n, c, _, _ = pred.shape\n",
    "\n",
    "        # softmax so that predicted map can be distributed in [0, 1]\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "        # one-hot vector of ground truth\n",
    "        one_hot_gt = one_hot(gt, c)\n",
    "\n",
    "        # boundary map\n",
    "        gt_b = F.max_pool2d(\n",
    "            1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        gt_b -= 1 - one_hot_gt\n",
    "\n",
    "        pred_b = F.max_pool2d(\n",
    "            1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        pred_b -= 1 - pred\n",
    "\n",
    "        # extended boundary map\n",
    "        gt_b_ext = F.max_pool2d(\n",
    "            gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        pred_b_ext = F.max_pool2d(\n",
    "            pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        # reshape\n",
    "        gt_b = gt_b.view(n, c, -1)\n",
    "        pred_b = pred_b.view(n, c, -1)\n",
    "        gt_b_ext = gt_b_ext.view(n, c, -1)\n",
    "        pred_b_ext = pred_b_ext.view(n, c, -1)\n",
    "\n",
    "        # Precision, Recall\n",
    "        P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
    "        R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
    "\n",
    "        # Boundary F1 Score\n",
    "        BF1 = 2 * P * R / (P + R + 1e-7)\n",
    "\n",
    "        # summing BF1 Score for each class and average over mini-batch\n",
    "        loss = torch.mean(1 - BF1)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.shape=torch.Size([8, 224, 224])\n",
      "label=tensor([[[1, 1, 1,  ..., 1, 1, 0],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 1, 0, 0],\n",
      "         [0, 1, 0,  ..., 1, 1, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 1, 0],\n",
      "         [1, 0, 1,  ..., 1, 1, 1],\n",
      "         [0, 0, 1,  ..., 0, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 1],\n",
      "         [1, 0, 1,  ..., 1, 1, 0],\n",
      "         [0, 0, 0,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 1],\n",
      "         [0, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 0, 0,  ..., 1, 1, 0],\n",
      "         ...,\n",
      "         [1, 1, 0,  ..., 1, 0, 0],\n",
      "         [1, 0, 1,  ..., 1, 1, 1],\n",
      "         [0, 1, 1,  ..., 1, 0, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 1, 1,  ..., 0, 1, 0],\n",
      "         [1, 0, 1,  ..., 1, 0, 1],\n",
      "         [0, 1, 1,  ..., 1, 1, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 0, 0, 1],\n",
      "         [1, 1, 0,  ..., 1, 1, 0]],\n",
      "\n",
      "        [[1, 0, 1,  ..., 1, 1, 1],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 1, 1],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 1, 0,  ..., 0, 1, 0],\n",
      "         [0, 1, 0,  ..., 1, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 1, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1],\n",
      "         [1, 1, 0,  ..., 1, 0, 1],\n",
      "         ...,\n",
      "         [1, 1, 0,  ..., 1, 1, 0],\n",
      "         [0, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 0, 0]]], device='cuda:0')\n",
      "n_classes=2\n",
      "tensor(0.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for debug\n",
    "import torch.optim as optim\n",
    "from torchvision.models import segmentation\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "img = torch.randn(8, 3, 224, 224).to(device)\n",
    "gt = torch.randint(0, 2, (8, 224, 224)).to(device)\n",
    "\n",
    "model = segmentation.fcn_resnet50(num_classes=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = BoundaryLoss()\n",
    "\n",
    "y = model(img)\n",
    "\n",
    "loss = criterion(y['out'], gt)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(30).reshape(5, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.max(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5],\n",
       "        [ 8, 11],\n",
       "        [14, 17],\n",
       "        [20, 23],\n",
       "        [26, 29]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
