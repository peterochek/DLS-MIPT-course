{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataset(images_name = \"lfw-deepfunneled\",\n",
    "                      dx=80,dy=80,\n",
    "                      dimx=64,dimy=64\n",
    "    ):\n",
    "\n",
    "    #read attrs\n",
    "    df_attrs = pd.read_csv(\"lfw_attributes.txt\",sep='\\t',skiprows=1,) \n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n",
    "\n",
    "\n",
    "    #read photos\n",
    "    photo_ids = []\n",
    "    for dirpath, dirnames, filenames in os.walk(images_name):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith(\".jpg\"):\n",
    "                fpath = os.path.join(dirpath,fname)\n",
    "                photo_id = fname[:-4].replace('_',' ').split()\n",
    "                person_id = ' '.join(photo_id[:-1])\n",
    "                photo_number = int(photo_id[-1])\n",
    "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
    "\n",
    "    photo_ids = pd.DataFrame(photo_ids)\n",
    "    # print(photo_ids)\n",
    "    #mass-merge\n",
    "    #(photos now have same order as attributes)\n",
    "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
    "\n",
    "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
    "\n",
    "    # print(df.shape)\n",
    "    #image preprocessing\n",
    "    all_photos = df['photo_path'].apply(skimage.io.imread)\\\n",
    "                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n",
    "                                .apply(lambda img: resize(img,[dimx,dimy]))\n",
    "\n",
    "    all_photos = np.stack(all_photos.values)#.astype('uint8')\n",
    "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n",
    "    \n",
    "    return all_photos, all_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, attrs = fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_photos, val_photos, train_attrs, val_attrs = train_test_split(data, attrs,\n",
    "                                                                    train_size=0.9, shuffle=False)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_photos, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_photos, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "\n",
    "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "\n",
    "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "\n",
    "        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(latent_variable_size, ngf*8*2*4*4)\n",
    "\n",
    "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd1 = nn.ReplicationPad2d(1)\n",
    "        self.d2 = nn.Conv2d(ngf*8*2, ngf*8, 3, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8, 1.e-3)\n",
    "\n",
    "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd2 = nn.ReplicationPad2d(1)\n",
    "        self.d3 = nn.Conv2d(ngf*8, ngf*4, 3, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
    "\n",
    "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd3 = nn.ReplicationPad2d(1)\n",
    "        self.d4 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
    "\n",
    "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd4 = nn.ReplicationPad2d(1)\n",
    "        self.d5 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
    "\n",
    "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd5 = nn.ReplicationPad2d(1)\n",
    "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
    "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
    "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
    "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
    "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
    "        h5 = h5.view(-1, self.ndf*8*4*4)\n",
    "\n",
    "        return self.fc1(h5), self.fc2(h5)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h1 = self.relu(self.d1(z))\n",
    "        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n",
    "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
    "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
    "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
    "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
    "\n",
    "        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_code = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=dim_code)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "reconstruction_function = nn.BCELoss()\n",
    "reconstruction_function.size_average = False\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(batch)\n",
    "        loss = loss_function(recon_batch, batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.batch[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(batch), (len(train_loader)*128),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.batch[0] / len(batch)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(train_loader)*128)))\n",
    "    return train_loss / (len(train_loader)*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "\n",
    "        torchvision.utils.save_image(data.data, '../imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "        torchvision.utils.save_image(recon_batch.data, '../imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(test_loader)*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_latent_space_arithmatics(items): # input is list of tuples of 3 [(a1,b1,c1), (a2,b2,c2)]\n",
    "    load_last_model()\n",
    "    model.eval()\n",
    "    data = [im for item in items for im in item]\n",
    "    data = [totensor(i) for i in data]\n",
    "    data = torch.stack(data, dim=0)\n",
    "    data = Variable(data, volatile=True)\n",
    "    if args.cuda:\n",
    "        data = data.cuda()\n",
    "    z = model.get_latent_var(data.view(-1, model.nc, model.ndf, model.ngf))\n",
    "    it = iter(z.split(1))\n",
    "    z = zip(it, it, it)\n",
    "    zs = []\n",
    "    numsample = 11\n",
    "    for i,j,k in z:\n",
    "        for factor in np.linspace(0,1,numsample):\n",
    "            zs.append((i-j)*factor+k)\n",
    "    z = torch.cat(zs, 0)\n",
    "    recon = model.decode(z)\n",
    "\n",
    "    it1 = iter(data.split(1))\n",
    "    it2 = [iter(recon.split(1))]*numsample\n",
    "    result = zip(it1, it1, it1, *it2)\n",
    "    result = [im for item in result for im in item]\n",
    "\n",
    "    result = torch.cat(result, 0)\n",
    "    torchvision.utils.save_image(result.data, '../imgs/vec_math.jpg', nrow=3+numsample, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_transition(items): # input is list of tuples of  (a,b)\n",
    "    load_last_model()\n",
    "    model.eval()\n",
    "    data = [im for item in items for im in item[:-1]]\n",
    "    data = [totensor(i) for i in data]\n",
    "    data = torch.stack(data, dim=0)\n",
    "    data = Variable(data, volatile=True)\n",
    "    if args.cuda:\n",
    "        data = data.cuda()\n",
    "    z = model.get_latent_var(data.view(-1, model.nc, model.ndf, model.ngf))\n",
    "    it = iter(z.split(1))\n",
    "    z = zip(it, it)\n",
    "    zs = []\n",
    "    numsample = 11\n",
    "    for i,j in z:\n",
    "        for factor in np.linspace(0,1,numsample):\n",
    "            zs.append(i+(j-i)*factor)\n",
    "    z = torch.cat(zs, 0)\n",
    "    recon = model.decode(z)\n",
    "\n",
    "    it1 = iter(data.split(1))\n",
    "    it2 = [iter(recon.split(1))]*numsample\n",
    "    result = zip(it1, it1, *it2)\n",
    "    result = [im for item in result for im in item]\n",
    "\n",
    "    result = torch.cat(result, 0)\n",
    "    torchvision.utils.save_image(result.data, '../imgs/trans.jpg', nrow=2+numsample, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_faces(num=5):\n",
    "    load_last_model()\n",
    "    model.eval()\n",
    "    z = torch.randn(num*num, model.latent_variable_size)\n",
    "    z = Variable(z, volatile=True)\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    recon = model.decode(z)\n",
    "    torchvision.utils.save_image(recon.data, '../imgs/rand_faces.jpg', nrow=num, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_last_model():\n",
    "    models = glob('../models/*.pth')\n",
    "    model_ids = [(int(f.split('_')[1]), f) for f in models]\n",
    "    start_epoch, last_cp = max(model_ids, key=lambda item:item[0])\n",
    "    print('Last checkpoint: ', last_cp)\n",
    "    model.load_state_dict(torch.load(last_cp))\n",
    "    return start_epoch, last_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_training():\n",
    "    start_epoch, _ = load_last_model()\n",
    "\n",
    "    for epoch in range(start_epoch + 1, start_epoch + args.epochs + 1):\n",
    "        train_loss = train(epoch)\n",
    "        test_loss = test(epoch)\n",
    "        torch.save(model.state_dict(), '../models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_model_to_cpu():\n",
    "    _, last_cp = load_last_model()\n",
    "    model.cpu()\n",
    "    torch.save(model.state_dict(), '../models/cpu_'+last_cp.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    resume_training()\n",
    "    # last_model_to_cpu()\n",
    "    # load_last_model()\n",
    "    # rand_faces(10)\n",
    "    # da = load_pickle(test_loader[0])\n",
    "    # da = da[:120]\n",
    "    # it = iter(da)\n",
    "    # l = zip(it, it, it)\n",
    "    # # latent_space_transition(l)\n",
    "    # perform_latent_space_arithmatics(l)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
