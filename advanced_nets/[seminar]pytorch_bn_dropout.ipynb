{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x4kC-U8dOpZU"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from tqdm.notebook import tqdm\n","\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","\n","from torchvision import transforms, datasets\n","\n","sns.set(font_scale=1.4, style=\"whitegrid\")"]},{"cell_type":"markdown","metadata":{"id":"4WQg5q6YmDku"},"source":["# Загрузка датасета\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmF5F28EmDkw","scrolled":true},"outputs":[],"source":["classes = (\"plane\", \"car\", \"bird\", \"cat\",\n","           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n","\n","def get_dataloaders(batch_size):\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","    trainset = datasets.CIFAR10(root=\"./data\", train=True,\n","                                            download=True, transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                              shuffle=True, num_workers=2)\n","    testset = datasets.CIFAR10(root=\"./data\", train=False,\n","                                           download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                             shuffle=False, num_workers=2)\n","    return trainloader, testloader"]},{"cell_type":"markdown","metadata":{"id":"OW14I7DorFEf"},"source":["В PyTorch датасетом считается любой объект, для которого определены методы `__len__(self)` и `__getitem__(self, i)`."]},{"cell_type":"markdown","metadata":{"id":"BEyxywtlmDkz"},"source":["# Код обучения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrFghgZ1mDk0"},"outputs":[],"source":["def fit(epochs, model, loss_func, opt, train_dl, valid_dl, lr_shed=None):\n","    train_losses = []\n","    val_losses = []\n","    valid_accuracies = []\n","    for epoch in range(epochs):\n","        model.train()\n","        loss_sum = 0\n","        for xb, yb in tqdm(train_dl):\n","            xb, yb = xb, yb\n","            \n","            loss = loss_func(model(xb), yb)\n","            loss_sum += loss.item()\n","            \n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","        train_losses.append(loss_sum / len(train_dl))\n","\n","        model.eval()\n","        loss_sum = 0\n","        correct = 0\n","        num = 0\n","        with torch.no_grad():\n","            for xb, yb in tqdm(valid_dl):\n","                xb, yb = xb, yb\n","                \n","                probs = model(xb)\n","                loss_sum += loss_func(probs, yb).item()\n","                \n","                _, preds = torch.max(probs, axis=-1)\n","                correct += (preds == yb).sum().item()\n","                num += len(xb)\n","                \n","        val_losses.append(loss_sum / len(valid_dl))\n","        valid_accuracies.append(correct / num)\n","\n","        if lr_shed is not None:\n","            lr_shed.step()\n","        \n","    return train_losses, val_losses, valid_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Go-15Cc-mDk1"},"outputs":[],"source":["def plot_trainig(train_losses, valid_losses, valid_accuracies):\n","    plt.figure(figsize=(12, 9))\n","    plt.subplot(2, 1, 1)\n","    plt.xlabel(\"epoch\")\n","    plt.plot(train_losses, label=\"train_loss\")\n","    plt.plot(valid_losses, label=\"valid_loss\")\n","    plt.legend()\n","    \n","    plt.subplot(2, 1, 2)\n","    plt.xlabel(\"epoch\")\n","    plt.plot(valid_accuracies, label=\"valid accuracy\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vY_MkdjmDk1"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n","        self.conv1 = nn.Conv2d(3, 6, 3)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(x.shape[0], -1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["d417eeabc4024c7894543bc76991c936","920a4cd69b214db6a27fbc795b1e11c9","a221b69ac3ba4c9098d3ebcdf6c9c22f","bfd8e770b99b4064843614e21b877ad9","d7095c743fab4c32b4b80ad1438c6d7d","89366428795742bfadf3929a482a4ed8","d8c27a1f0c70497a980152af039682a1","dbb4f724684e4e36a4f66c9e2de9ce32","f2542c3e671548e484a7dee54c8f725a","e7d5d910ce50409a8b795fa593aa3cff","b5618653477140d7ac527435410e4c2a","616efd9ce42f4fecb249aca5a65f7766","263ba22dd0d643dd8c1779b7cf4e715b","7a2be2208a114705bc684162d7a3afbc","b233528353864ef1984165f1c3810f9f","311384f5580f44b895dc21a5dbb2a129","7eec8160de8c453b91ea6250f3fff99e","a12096f3b9bd4e12b83b322f200c6a93","914db12406fe4453bd1998bd3fd7200c","1bc9db4447b6423c8fc8d95dd93fb664"]},"id":"jOgn0NObmDk2","outputId":"6cb668c8-5a45-44b1-f25d-2189e4ba3c9f","scrolled":true},"outputs":[],"source":["model = Model()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","info = fit(10, model, criterion, optimizer, *get_dataloaders(4))\n","plot_trainig(*info)"]},{"cell_type":"markdown","metadata":{"id":"na-IntqtmDk3"},"source":["# BatchNorm\n","Ранее мы обсуждали, что для линейных моделей очень важно нормировать признаки перед подачей на вход. Когда мы работаем с нейронными сетями мы тоже нормируем вход, но есть ли какой-то способ нормировать признаки на внутренних слоях нейроной сети?\n","\n","Да, существует несколько метдов нормировки признаков (BatchNorm, LayerNorm, InstanceNorm, etc). Научимся применять BatchNorm.\n"]},{"cell_type":"markdown","metadata":{"id":"ltX33A8zmDk4"},"source":["### BatchNorm, математика\n","\n","Если коротко, то BatchNorm для каждого признака вычитает среднее значение по батчу и делит на стандартное отклонение по батчу, потом домножает все признаки на вес $\\gamma$ и прибавляет вес $\\beta$. При этом возникает вопрос, что если мы используем модель уже для предсказаний и можем запускать ее только на одном примере.\n","\n","BatchNorm работает по разному во время обучения и предсказний:\n","\n","\n","**Во время обучения**. Пусть батч состоит из $\\mathbf{x_i}$ (каждый $\\mathbf{x_i}$ - вектор, подающийся на вход). Тогда\n","$$\\begin{aligned}\n","\\mu_{\\mathcal{B}} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m} x_{i} \\\\\n","\\sigma_{\\mathcal{B}}^{2} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}-\\mu_{\\mathcal{B}}\\right)^{2} \\\\\n","\\widehat{x}_{i} & \\leftarrow \\frac{x_{i}-\\mu_{\\mathcal{B}}}{\\sqrt{\\sigma_{\\mathcal{B}}^{2}+\\epsilon}} \\\\\n","y_{i} & \\leftarrow \\gamma \\widehat{x}_{i}+\\beta \\equiv \\mathrm{B} \\mathrm{N}_{\\gamma, \\beta}\\left(x_{i}\\right)\n","\\end{aligned}$$\n","\n","**Во время предсказания**. Мы делаем то же самое, но у нас нет батча. Поэтому в качестве $\\mu_{\\mathcal{B}}$ и $\\sigma_{\\mathcal{B}}$ мы используем среднее и стандартное отклонение признака во всем датасете. Обычно нам не хочется после обучения еще раз применять сеть ко всем примерам из обучающего датасета, чтобы вычислить эти статистики и мы вместо них используем экспоненциально затухающее среднее последних батчей."]},{"cell_type":"markdown","metadata":{"id":"I68BvqkAmDk6"},"source":["### BatchNorm, что он дает?\n","\n","* Более быстрое обучение. Болшие learning_rate\"ы.\n","* Обучение более глубоких сетей.\n","* Регуляризация.\n","* Повышение точности моделей."]},{"cell_type":"markdown","metadata":{"id":"snZZgj9ymDk6"},"source":["### BatchNorm для Conv слоев\n","\n","Для сверточных слоев мы хотим следующее свойство \"если в разных частях картинки находятся одинаковые наборы пикселей, то соответствующие выходы сверточного слоя будут одинаковыми\". Если бы мы применяли алгоритм, который описан выше, то получилось бы так, что для пикселей, находящихся в 1 канале в координате (1,1) среднее и стд могли бы получиться не такими же как для пикселя в 1 канале в координате (10, 10). Тогда даже если изначально в них были одинаковые значения, то после BatchNorm они стали бы разными. \n","\n","Есть простое решение проблемы. Мы будем усреднять не только по batch_size координате, но и height, width координатам. Чтобы лучше объяснить используем псевдокод (origin https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network):\n","\n","На вход подается тензор (многомерный массив) размера [B, H, W, C]. Где B - количество батчей, H - высота картинок, W - ширина картинок, а C - количество каналов. Тогда обычный батчнорм выполнял бы нормирование так:\n","```python\n","# t is the incoming tensor of shape [B, H, W, C]\n","# mean and stddev are computed along 0 axis and have shape [H, W, C]\n","mean = mean(t, axis=0)\n","stddev = stddev(t, axis=0)\n","for i in 0..B-1:\n","  out[i,:,:,:] = norm(t[i,:,:,:], mean, stddev)\n","```\n","\n","В то время как батчнорм для сверточных сетей (BatchNorm2D в PyTorch):\n","\n","```python\n","# t is still the incoming tensor of shape [B, H, W, C]\n","# but mean and stddev are computed along (0, 1, 2) axes and have just [C] shape\n","mean = mean(t, axis=(0, 1, 2))\n","stddev = stddev(t, axis=(0, 1, 2))\n","for i in 0..B-1, x in 0..H-1, y in 0..W-1:\n","  out[i,x,y,:] = norm(t[i,x,y,:], mean, stddev)\n","```"]},{"cell_type":"markdown","metadata":{"id":"GpZL0WTnmDk7"},"source":["### BatchNorm, порядок применения\n","\n","В оригинальной статье (http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43442.pdf) для сверточных слоев батчнорм предлагают использовать сразу после свертки до активации. Я не смог найти статей, которые бы исследовали, нужно ли делать BN до или после активации, и, похоже, однозначного мнения нет + в более сложных архитектурах (ResNet\"ы) исследователи обычно экспериментируют и ставят BN в разные места."]},{"cell_type":"markdown","metadata":{"id":"KKpeA1z7mDk_"},"source":["### BatchNorm, PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDGHfIenmDlA"},"outputs":[],"source":["class ModelBatchNorm(nn.Module):\n","    def __init__(self):\n","        super(ModelBatchNorm, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n","        self.conv1 = nn.Conv2d(3, 6, 3)\n","        self.bn1 = nn.BatchNorm2d(6)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        self.bn2 = nn.BatchNorm2d(16)\n","        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n","        self.bn3 = nn.BatchNorm1d(120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.bn1(F.max_pool2d(F.relu(self.conv1(x)), (2, 2)))\n","        x = self.bn2(F.max_pool2d(F.relu(self.conv2(x)), 2))\n","        x = x.view(x.shape[0], -1)\n","        x = self.bn3(F.relu(self.fc1(x)))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["90e0d5022786436ca6084c5d1f8961d6","08bf2885a4e047dca549d2ff1b769d47","936d57dfe922461cb3f9e9a3a23cc528","066613840ee34bbcad3f9a4856dc3a88","bdd2554741804031877fde60624b184e","b7bab96faec5414784e2631aff03812d","850435b4ae084d1aad82dca73cb38f9b","bc90853240fc4df69aef4145765f7986","c193861633aa47d4a67fb14eeda6b19f","560e0c9343374e868877ce63ad8909f4","bf85156caffa46f28dddf06ae0d23a60","0a54687e97634eb691921504b6144618","da7251163f984a809f2397d7935ca2d3","0a07fbe043364b748bbc1490eb285125","0ca8a393a54546f3a7a5ba31e71dcb89","75a4cfb18bd645b582a770ecee128136","671b4efb381445529625fc3013fa51e3","2aafc529503448d8b68e1a4c3e152ac6","c88fbb491f774ca498a92859574811ad","3f9bb629afc94280ba1fa1051118a7f9"]},"id":"_sEvHh8EmDlB","outputId":"a0e1ead6-a39e-4b7b-f360-6e736ecde80c"},"outputs":[],"source":["model = ModelBatchNorm()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","info = fit(10, model, criterion, optimizer, *get_dataloaders(4))\n","plot_trainig(*info)"]},{"cell_type":"markdown","metadata":{"id":"k4z81RsMmDlF"},"source":["Вспомните как выглядели формулы для BatchNorm: если размер батча равен 1, то $\\sigma = 0$, и у нас есть деление на ноль. PyTorch не умеет обрабатывать такой случай и падает:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["4113a6742eaf4c50a405ce7de15ea5f3"]},"id":"5LV2ql_3mDlH","outputId":"2a3750f2-7f0b-467f-de4b-ef4200a75938"},"outputs":[],"source":["model = ModelBatchNorm()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","fit(1, model, criterion, optimizer, *get_dataloaders(batch_size=1))"]},{"cell_type":"markdown","metadata":{"id":"vFh4o5s8mDlI"},"source":["# Dropout\n","\n","Дропаут это еще один необычный слой, который используется в нейронных сетях. У него есть один гиперпараметр $p$.\n","\n","Идея дропаута состоит в том, что во время обучения мы зануляем случайную часть входа и отдаем вход дальше (для каждого числа мы подбрасываем монетку и с вероятностью $p$ зануляем это число). \n","\n","Дропаут позволяет тренировать более устойчивые сети и избегать переобучения. "]},{"cell_type":"markdown","metadata":{"id":"sk_UeJG1mDlJ"},"source":["### Dropout, механика работы.\n","\n","Как мы сказали выше, dropout зануляет случайную часть входов и отдает их дальше. Допустим $p=0.5$ (достаточное популярное значение). Тогда мы просто убираем половину всего входа! Такое сильное воздействие явно плохо повлияет на качество нашей модели, поэтому мы делаем зануление только во время обучения.\n","\n","**Во время обучения**: для каждого числа во входе подбрасываем монетку и зануляем его с вероятностью $p$. Выход умножаем на $\\frac{1}{1-p}$, чтобы дисперсия выходов осталось такой же, как и на входе.\n","\n","**Во время предсказаний**: ничего не делаем)."]},{"cell_type":"markdown","metadata":{"id":"oEjBjfinmDlJ"},"source":["### Dropout, что дает?\n","\n","* Сеть выучивает более устойчивые представления на внутренних слоях.\n","* Сильно увеличивает число итераций, которые нужны для сходимости.\n","* Можно получить интерпретацию, которая говорит, что дропаут усредняет выходы большо числа нейросетей с $p|W|$ нейронами на предыдущем слоев. \n","\n","Дропаут вызывает интересный эффект: в начале обучения качество на тестовом датасете выше, чем на обучающем. Потому что для обучающего датасета у нас есть зануление, которое сильно портит предсказания."]},{"cell_type":"markdown","metadata":{"id":"kzGtNEXlmDlK"},"source":["### Dropout, взаимодействие с BatchNorm.\n","\n","Статья, исследующая, почему исопльзование дропаута и батчнорма вместе часто ведет к более плохим результатам, чем их использование по-отдельности - https://arxiv.org/pdf/1801.05134.pdf\n","\n","Картинка из статьи, объясняющая проблему:\n","![img](https://media.arxiv-vanity.com/render-output/3934414/x1.png)\n","\n","(Если совсем коротко, то при наличии дропаута во время обучения и во время предсказаний выходы дропаута имеют разное распределение. Поэтому статистики, которые batchnorm считает для применения во время предсказаний, оказываются неверными.)\n","\n","Решение: если вы хотите использовать батчнорм и дропаут в одной сети, то все Dropout\"ы должны идти после BatchNorm\"ов."]},{"cell_type":"markdown","metadata":{"id":"BG_QDH1smDlK"},"source":["### Dropout, PyTorch\n","\n","В PyTorch есть `F.dropout(x, p=p)` и слой `nn.Dropout(p=p)`. В чем их отличие? `F.dropout(x, p=p)` не будет изменять свое поведение в заивимости от того, в каком стостянии сейчас модель (train, eval).\n","\n","Теперь чуть подробнее:\n","\n","Когда вы вызываете model.train()/model.eval() PyTorch проходится по всем переменным класса и если видит там наследника nn.Module или nn.ModuleList, то также меняет состояние для всех найденных модулей. Т.е. версия со слоем будет автоматически работать с train/eval состяниями. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHAgRfpcmDlL"},"outputs":[],"source":["class ModelDropout(nn.Module):\n","    def __init__(self):\n","        super(ModelDropout, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n","        self.conv1 = nn.Conv2d(3, 6, 3)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(x.shape[0], -1)\n","        x = self.dropout(F.relu(self.fc1(x)))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["09f09932073f48b8b17f3e58e07feef2","6ba9dea883474352b56cd448f461537a","9588033eb7f6406a8c722f11a2322b75","08ab3d3795524c73a6a4bcfb8c954c6e","f6216e7ef0cb42ed8347d8ebae5759ec","865e09aa457e450e8e76f853b239d0e9","705e7f115e07438b8cf7436ecd4e8865","74fb5a3a50b44316b0a359d033efaf10","fcd6f231a8a549f298909965a270cdc6","fd8acce5ebc24f8382975b162c7a71b7","d319f84af4ce4eac964ae0cf4b270aef","f2e44fe371774996b596477e1257fee0","42326457c01d48f3a94f5984ce892525","b0ad9198cd174ee0824b487c86224777","0f1471bece2b4004b217fa3542f59ff6","1691442544584c2ca54e377e504b78d2","2522813edd0f459c8975ed6f36ac8cee","957a317602644424b22c04eb82355cde","29065f0252b44073a83c0faee0a7fa8f","a10fabb9acb34621aefc38425f12bdb1"]},"id":"29FOTh0FmDlM","outputId":"b1d67354-d58b-48b5-963e-b194aa76f94d"},"outputs":[],"source":["model = ModelDropout()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.5)\n","\n","info = fit(10, model, criterion, optimizer, *get_dataloaders(4), lr_shed=lr_scheduler)\n","plot_trainig(*info)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"[seminar, adv]pytorch_bn_dropout.ipynb","provenance":[]},"interpreter":{"hash":"5eb2e0c23f8e38f19a3cfe8ad2d7bbb895a86b1e106b247f2b169180d03d2047"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
